{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing Libraries and dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries \n",
    "import pandas as pd\n",
    "import talib\n",
    "import yfinance as yf\n",
    "import spacy\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.express as px\n",
    "import nltk\n",
    "import re\n",
    "\n",
    "\n",
    "from spacy.lang.en import English\n",
    "from spacy.matcher import PhraseMatcher\n",
    "from scipy.stats import pearsonr, spearmanr\n",
    "# from nltk.tokenize import word_tokenize\n",
    "# from nltk.tag import pos_tag\n",
    "# from nltk.corpus import stopwords\n",
    "# from nltk.probability import FreqDist\n",
    "from nltk.sentiment import SentimentIntensityAnalyzer\n",
    "# import nltk\n",
    "from textblob import TextBlob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import importlib\n",
    "# importlib.reload(nltk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "nltk.download('punkt')\n",
    "nltk.download('wordnet')\n",
    "nltk.download('vader_lexicon')\n",
    "nltk.download('averaged_perceptron_tagger')\n",
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing dataset from file \n",
    "dataset = pd.read_csv('../data/raw_analyst_ratings.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Descriptive Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "headline_lengths = [len(headline) for headline in dataset['headline']]\n",
    "total_headlines = len(dataset['headline'])\n",
    "print(f\"The total headlines are {total_headlines}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "min_length = min(headline_lengths)\n",
    "max_length = max(headline_lengths)\n",
    "average_length = sum(headline_lengths) / total_headlines\n",
    "print(f\"The minimum, maximum and avarage length of a headlines are {min_length}, {max_length} and {round(average_length, 2)} respectively.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "article_count = dataset['publisher'].value_counts()\n",
    "print(f\"The number of articles published are {article_count}.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset[\"date\"] = pd.DataFrame(dataset[\"date\"])\n",
    "dataset['date'] = pd.to_datetime(dataset['date'], errors='coerce')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['day_of_week'] = dataset['date'].dt.day_name()\n",
    "dataset['month'] = dataset['date'].dt.month\n",
    "dataset['year'] = dataset['date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "day_of_week_counts = dataset['day_of_week'].value_counts().sort_index()\n",
    "plt.plot(day_of_week_counts.index, day_of_week_counts.values)\n",
    "plt.xlabel('Day of the Week')\n",
    "plt.ylabel('Publication Frequency')\n",
    "plt.title('Publication Frequency by Day of the Week')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "month_counts = dataset['month'].value_counts().sort_index()\n",
    "plt.plot(month_counts.index, month_counts.values)\n",
    "plt.xlabel('Month')\n",
    "plt.ylabel('Publication Frequency')\n",
    "plt.title('Publication Frequency by Month')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Text Analysis (Sentiment analysis & Topic Modeling)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for headline in dataset['headline'].head(10):\n",
    "    sentiment = SentimentIntensityAnalyzer().polarity_scores(headline)\n",
    "    compound_score = sentiment['compound']\n",
    "    \n",
    "    if compound_score > 0:\n",
    "        print(f\"Positive: {headline}\")\n",
    "    elif compound_score < 0:\n",
    "        print(f\"Negative: {headline}\")\n",
    "    else:\n",
    "        print(f\"Neutral: {headline}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')\n",
    "tokenizer = English().tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_keywords(text):\n",
    "    doc = nlp(text)\n",
    "    \n",
    "    keywords = []\n",
    "    \n",
    "    for chunk in doc.noun_chunks:\n",
    "        keywords.append(chunk.text)\n",
    "    \n",
    "    topic_phrases = [\"FDA approval\", \"price target\"]\n",
    "    \n",
    "    matcher = PhraseMatcher(nlp.vocab)\n",
    "    patterns = [nlp(phrase) for phrase in topic_phrases]\n",
    "    matcher.add(\"TopicPhrases\", None, *patterns)\n",
    "    \n",
    "    matches = matcher(doc)\n",
    "    for match_id, start, end in matches:\n",
    "        matched_span = doc[start:end]\n",
    "        keywords.append(matched_span.text)\n",
    "    \n",
    "    return keywords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['keywords'] = dataset[\"headline\"].head().apply(extract_keywords)\n",
    "print(dataset['keywords'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Time Series Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publication_counts = dataset.groupby(dataset['date'].dt.date).size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "plt.plot(publication_counts.index, publication_counts.values)\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Publication Frequency')\n",
    "plt.title('Publication Frequency Over Time')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hourly_counts = dataset.set_index('date').resample('H').size()\n",
    "print(hourly_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(10, 6))\n",
    "dataset['date'].dt.hour.hist(bins=24, edgecolor='black')\n",
    "plt.xlabel('Hour')\n",
    "plt.ylabel('Number of News Articles')\n",
    "plt.title('Distribution of News Publishing Times')\n",
    "plt.xticks(range(0, 24))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Publisher Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "publisher_counts = dataset['publisher'].value_counts().head(5).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "ax = publisher_counts.plot(kind='bar', color='steelblue')\n",
    "ax.set_xlabel('Publisher')\n",
    "ax.set_ylabel('Number of Articles')\n",
    "ax.set_title('Publisher Contribution to News Feed')\n",
    "ax.set_xticklabels(publisher_counts.index, rotation=45, ha='right')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "top_publishers = publisher_counts.head(5).index\n",
    "subset_data = dataset[dataset['publisher'].isin(top_publishers)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for publisher in top_publishers:\n",
    "    publisher_data = subset_data[subset_data['publisher'] == publisher]\n",
    "    print(publisher_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_domain(email):\n",
    "    match = re.search(\"@[\\w.]+\", email)\n",
    "    if match:\n",
    "        return match.group()[1:]\n",
    "    else:\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset['domain'] = dataset['publisher'].apply(extract_domain)\n",
    "domain_counts = dataset['domain'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12, 6))\n",
    "domain_counts.plot(kind='bar')\n",
    "plt.xlabel('Domain')\n",
    "plt.ylabel('Number of Contributions')\n",
    "plt.title('Domain Contribution to News Feed')\n",
    "plt.xticks(rotation=45)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Stock price fetching "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = dataset[['date', 'stock']]\n",
    "dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = dataset['stock'].unique()\n",
    "unique_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped_data = dataset.groupby('stock')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "earliest_dates = grouped_data['date'].min()\n",
    "latest_dates = grouped_data['date'].max()\n",
    "\n",
    "print(earliest_dates, latest_dates)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Quantitative analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock, earliest_date in earliest_dates.items():\n",
    "    latest_date = latest_dates[stock]\n",
    "    \n",
    "    stock_data = yf.download(stock, start=earliest_date, end=latest_date)\n",
    "    \n",
    "    stock_data['stock'] = stock\n",
    "    stock_dataset = pd.concat([stock_dataset, stock_data], ignore_index=True)\n",
    "\n",
    "print(stock_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reason = talib.RSI(stock_dataset[\"Close\"])\n",
    "print(reason)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "macd, signal, hist = talib.MACD(stock_dataset[\"Close\"], fastperiod=12, slowperiod=26, signalperiod=9)\n",
    "macd, signal, hist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "stock_dataset['returns'] = stock_dataset['Close'].pct_change()\n",
    "\n",
    "stock_dataset['moving_average'] = stock_dataset['Close'].rolling(window=3).mean()\n",
    "\n",
    "stock_dataset['cumulative_returns'] = (1 + stock_dataset['returns']).cumprod()\n",
    "\n",
    "stock_dataset['vwap'] = (stock_dataset['Close'] * stock_dataset['Volume']).cumsum() / stock_dataset['Volume'].cumsum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8, 6))\n",
    "plt.hist(stock_dataset['returns'].dropna(), bins=30, edgecolor='black')\n",
    "plt.xlabel('Daily Returns')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Daily Returns')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Task-4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 7. Correlation between news and stock movement"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_values = dataset['stock'].unique()\n",
    "stock_dataset = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for stock in unique_values:\n",
    "    stock_data = yf.Ticker(stock)\n",
    "    \n",
    "    stock_dataset = pd.concat([stock_dataset, stock_data.history(period=\"max\")])\n",
    "\n",
    "stock_dataset.reset_index(drop=False, inplace=True)\n",
    "stock_dataset.rename(columns={'Date': 'date'}, inplace=True)\n",
    "stock_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged_dataset = pd.merge(dataset, stock_dataset, on='date', how='inner')\n",
    "merged_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for headline in dataset[\"headline\"].head(20):\n",
    "    blob = TextBlob(headline)\n",
    "    sentiment = blob.sentiment.polarity\n",
    "    dataset[\"sentiment\"] = sentiment\n",
    "\n",
    "    if sentiment > 0:\n",
    "        sentiment_label = \"Positive\"\n",
    "    elif sentiment < 0:\n",
    "        sentiment_label = \"Negative\"\n",
    "    else:\n",
    "        sentiment_label = \"Neutral\"\n",
    "\n",
    "    print(f\"Headline: {headline}\")\n",
    "    print(f\"Sentiment: {sentiment_label}\")\n",
    "    print(f\"Headline: {dataset['sentiment']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.sort_values('date', inplace=True)\n",
    "dataset['return'] = stock_df['Close'].pct_change() * 100\n",
    "print(dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_sentiments = dataset.groupby('date')['sentiment'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "daily_returns = dataset.groupby('date')['return'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_output  = pd.merge(daily_sentiments, daily_returns, on='date', how='inner')\n",
    "dataset_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spearman_corr, spearman_pvalue = spearmanr(df['sentiment'], df['return'])\n",
    "print(f\"Spearman correlation coefficient: {spearman_corr}\")\n",
    "print(f\"P-value: {spearman_pvalue}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
